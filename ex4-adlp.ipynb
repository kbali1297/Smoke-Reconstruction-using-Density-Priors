{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004312,
     "end_time": "2022-06-28T07:37:37.37764",
     "exception": false,
     "start_time": "2022-06-28T07:37:37.373328",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Exercise 4: Smoke Reconstruction\n",
    "\n",
    "The goal of this exercise is to reconstruct 2D smoke simulations from only the projected smoke density.\n",
    "\n",
    "The observations consist of the projected smoke densities along $x$ and $y$ over 20 time steps and the reconstruction must contain the 2D smoke reconstructions as well as the velocity fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:51:48.223824Z",
     "iopub.status.busy": "2022-07-09T09:51:48.222886Z",
     "iopub.status.idle": "2022-07-09T09:52:00.263555Z",
     "shell.execute_reply": "2022-07-09T09:52:00.26248Z",
     "shell.execute_reply.started": "2022-07-09T09:51:48.223758Z"
    },
    "papermill": {
     "duration": 17.200575,
     "end_time": "2022-06-28T07:37:54.581585",
     "exception": false,
     "start_time": "2022-06-28T07:37:37.38101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: phiflow in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from phiflow) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from phiflow) (1.7.3)\n",
      "Requirement already satisfied: numpy in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from phiflow) (1.21.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from matplotlib->phiflow) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/kartik/anaconda3/envs/pytorch-tf-jax/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->phiflow) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.1.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/kartik/anaconda3/envs/pytorch-tf-jax/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!pip install phiflow\n",
    "from phi.flow import *\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005084,
     "end_time": "2022-06-28T07:37:55.321772",
     "exception": false,
     "start_time": "2022-06-28T07:37:55.316688",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Insert your reconstruction algorithm / network here, replacing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:00.267756Z",
     "iopub.status.busy": "2022-07-09T09:52:00.26549Z",
     "iopub.status.idle": "2022-07-09T09:52:00.283286Z",
     "shell.execute_reply": "2022-07-09T09:52:00.282276Z",
     "shell.execute_reply.started": "2022-07-09T09:52:00.267718Z"
    }
   },
   "outputs": [],
   "source": [
    "''' DATASET GENERATION FOR EXERCISE 4'''\n",
    "from phi.torch.flow import * \n",
    "from phi.field._grid import unstack_staggered_tensor\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:00.284948Z",
     "iopub.status.busy": "2022-07-09T09:52:00.284553Z",
     "iopub.status.idle": "2022-07-09T09:52:00.296533Z",
     "shell.execute_reply": "2022-07-09T09:52:00.295366Z",
     "shell.execute_reply.started": "2022-07-09T09:52:00.284912Z"
    }
   },
   "outputs": [],
   "source": [
    "# pads centered grid tensor to staggered size\n",
    "def cen_to_stag(centered_grid):\n",
    "    padded_values = math.pad(centered_grid.values, {'x':(0,1), 'y':(0,1)}, mode=math.extrapolation.ZERO)\n",
    "    return padded_values\n",
    "\n",
    "# reduces staggered size tensor to centered tensor\n",
    "def reduce_to_cen(reduce_tensor):\n",
    "    return math.pad(reduce_tensor, {'x':(0,-1), 'y':(0,-1)}, mode=math.extrapolation.ZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:00.300218Z",
     "iopub.status.busy": "2022-07-09T09:52:00.299641Z",
     "iopub.status.idle": "2022-07-09T09:52:35.075816Z",
     "shell.execute_reply": "2022-07-09T09:52:35.074837Z",
     "shell.execute_reply.started": "2022-07-09T09:52:00.300183Z"
    }
   },
   "outputs": [],
   "source": [
    "k=32 # number of discrete cells per dimsension\n",
    "Nb = 100\n",
    "Nt = 20\n",
    "# generate random buoyant smoke spheres \n",
    "def generate_inflow(shape: math.Shape, bounds=Box(x=100, y=100)):\n",
    "    centers = math.random_uniform(shape, channel(vector='x,y')) * bounds.size * (0.5, .3) + (25,10.)\n",
    "    sizes =  math.random_uniform(shape) *4 + 3\n",
    "    strengths = 1\n",
    "    return CenteredGrid(SoftGeometryMask(Sphere(centers, radius=sizes)), 0, x=k, y=k, bounds=bounds) * strengths\n",
    "\n",
    "# dataset size in batch dimension\n",
    "INFLOW = generate_inflow(batch(batch=Nb) & instance(inflows=2)) \n",
    "velocity = StaggeredGrid((0, 0), 0, x=k, y=k, bounds=Box(x=100, y=100))  # or CenteredGrid(...)\n",
    "smoke = CenteredGrid(INFLOW, extrapolation.BOUNDARY, x=k, y=k, bounds=Box(x=100, y=100))\n",
    "pressure = None\n",
    "\n",
    "# @math.jit_compile \n",
    "def step(v, s, p, dt=5.):\n",
    "    s = advect.mac_cormack(s, v, dt) #+ INFLOW\n",
    "    buoyancy = s * (0, 0.1) @ v  # resamples smoke to velocity sample points\n",
    "    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt\n",
    "    v, p = fluid.make_incompressible(v, (), Solve('auto', 1e-5, 0))\n",
    "    return v, s, p\n",
    "\n",
    "smokes, velocities, pxs, pys = [], [], [], []\n",
    "for i in range(Nt):\n",
    "    velocity, smoke, pressure = step(velocity, smoke, pressure)\n",
    "    smokes.append(cen_to_stag(smoke).native(['batch','x','y']))\n",
    "    velocities.append(velocity.staggered_tensor().native(['batch', 'x', 'y','vector']))\n",
    "    px =torch.mean(smokes[-1], axis=1)\n",
    "    py =torch.mean(smokes[-1], axis=2)\n",
    "    pxs.append(px)\n",
    "    pys.append(py)\n",
    "\n",
    "# input data is stored with following dimensions: [batch, time, axis, (projection_x, projection_y)]\n",
    "# ouput data is stored with following dimensions: [batch, time, x, y, (smoke, vx, vy)]\n",
    "smokes = torch.permute(torch.stack(smokes),[1,0,2,3])\n",
    "velocities = torch.permute(torch.stack(velocities),[1,0,2,3,4])\n",
    "pxs =  torch.permute(torch.stack(pxs),[1,0,2])\n",
    "pys =  torch.permute(torch.stack(pys),[1,0,2])\n",
    "input_data = torch.stack([pxs,pys], dim=-1).cpu().numpy()\n",
    "output_data = torch.cat([torch.unsqueeze(smokes[:,:], -1), velocities[:,:]],-1).cpu().numpy()\n",
    "\n",
    "np.save('training_input_ex4',input_data)\n",
    "np.save('training_output_ex4',output_data)\n",
    "np.savetxt('training_input_ex4.csv', input_data.flatten(), delimiter=',')\n",
    "np.savetxt('training_output_ex4.csv', output_data.flatten(), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:35.079432Z",
     "iopub.status.busy": "2022-07-09T09:52:35.078577Z",
     "iopub.status.idle": "2022-07-09T09:52:35.093706Z",
     "shell.execute_reply": "2022-07-09T09:52:35.092831Z",
     "shell.execute_reply.started": "2022-07-09T09:52:35.07939Z"
    }
   },
   "outputs": [],
   "source": [
    "''' SIMULATOR STEP BASED ON TENSORS '''\n",
    "from phi.field._grid import unstack_staggered_tensor\n",
    "state =math.tensor(output_data[:10], batch('batch', 'time'), spatial('x,y'), channel(features='rho,vx,vy'))\n",
    "k=32\n",
    "def cen_to_stag(centered_grid):\n",
    "    padded_values = math.pad(centered_grid.values, {'x':(0,1), 'y':(0,1)}, mode=math.extrapolation.ZERO)\n",
    "    return padded_values\n",
    "\n",
    "def reduce_to_cen(reduce_tensor):\n",
    "    return math.pad(reduce_tensor, {'x':(0,-1), 'y':(0,-1)}, mode=math.extrapolation.BOUNDARY)\n",
    "\n",
    "def step(state, dt=5.):\n",
    "    s = CenteredGrid(reduce_to_cen(state.features['rho']), extrapolation.BOUNDARY, x=k, y=k, bounds=Box(x=100, y=100))\n",
    "    unstacked_velocity = unstack_staggered_tensor(math.rename_dims(state.features['vx,vy'], 'features', 'vector'), extrapolation=math.extrapolation.ZERO)\n",
    "    v = StaggeredGrid(unstacked_velocity, 0, x=k, y=k, bounds=Box(x=100, y=100))\n",
    "    s = advect.mac_cormack(s, v, dt) #+ INFLOW\n",
    "    buoyancy = s * (0, 0.1) @ v  # resamples smoke to velocity sample points\n",
    "    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt\n",
    "    v,_= fluid.make_incompressible(v, (), Solve('auto', 1e-5, 0))\n",
    "    v = v.staggered_tensor()\n",
    "    return math.stack([cen_to_stag(s), v.vector['x'], v.vector['y']], channel(features='rho,vx,vy')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:35.095867Z",
     "iopub.status.busy": "2022-07-09T09:52:35.095364Z",
     "iopub.status.idle": "2022-07-09T09:52:35.69844Z",
     "shell.execute_reply": "2022-07-09T09:52:35.697462Z",
     "shell.execute_reply.started": "2022-07-09T09:52:35.095759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m(batchᵇ=10, xˢ=33, yˢ=33, featuresᶜ=rho,vx,vy)\u001b[0m \u001b[93mfloat32\u001b[0m  \u001b[94m1.57e-08 ± 2.8e-08\u001b[0m \u001b[37m(0e+00...4e-07)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# CHECK IF RESULTS ARE THE SAME\n",
    "evolv = step(state.time[0])\n",
    "print(math.abs(evolv-state.time[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:35.700733Z",
     "iopub.status.busy": "2022-07-09T09:52:35.699742Z",
     "iopub.status.idle": "2022-07-09T09:52:35.738914Z",
     "shell.execute_reply": "2022-07-09T09:52:35.737931Z",
     "shell.execute_reply.started": "2022-07-09T09:52:35.700675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m(batchᵇ=100, timeᵇ=20, axisˢ=33, projectionᶜ=x,y)\u001b[0m \u001b[93mfloat32\u001b[0m  \u001b[94m0.015 ± 0.029\u001b[0m \u001b[37m(0e+00...2e-01)\u001b[0m\n",
      "\u001b[92m(batchᵇ=100, timeᵇ=20, xˢ=33, yˢ=33, featuresᶜ=rho,vx,vy)\u001b[0m \u001b[93mfloat32\u001b[0m  \u001b[94m0.005 ± 0.126\u001b[0m \u001b[37m(-8e-01...2e+00)\u001b[0m\n",
      "\u001b[92m(batchᵇ=1, timeᵇ=20, axisˢ=33, projectionᶜ=x,y)\u001b[0m \u001b[93mfloat32\u001b[0m  \u001b[94m0.073 ± 0.068\u001b[0m \u001b[37m(0e+00...4e-01)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Path to training_input_ex4.csv\n",
    "input_file_path = \"./training_input_ex4.npy\"\n",
    "output_file_path = \"./training_output_ex4.npy\"\n",
    "test_file_path =  \"./test_input_ex4.npy\"\n",
    "# Loads training input, 100 training samples (batch), each sample is a 20-step time-series, axis is the spatial length (33 discrete point), and provides x&y projections\n",
    "#loaded_input = numpy.genfromtxt(input_file_path, delimiter=',').reshape(100,20,33,2)\n",
    "loaded_input = np.load(input_file_path).reshape(Nb,Nt,33,2)\n",
    "observation = tensor(loaded_input, batch(batch=Nb,time=Nt), spatial(axis=33), channel(projection='x,y'))\n",
    "\n",
    "# Loads training labels, 100 training samples (batch), each sample is a 20-step time-series, 33x33 domain, contains smoke density (rho), and velocity (vx, vy)\n",
    "#loaded_output = numpy.genfromtxt(output_file_path, delimiter=',').reshape(100,20,33,33,3)\n",
    "loaded_output = numpy.load(output_file_path).reshape(Nb,Nt,33,33,3)\n",
    "label = tensor(loaded_output, batch(batch=Nb,time=Nt), spatial(x=33, y=33), channel(features='rho,vx,vy'))\n",
    "\n",
    "print(observation)\n",
    "print(label)\n",
    "\n",
    "loaded_test_input = np.load(test_file_path).reshape(-1,20,33,2)\n",
    "observation_test = tensor(loaded_test_input, batch(batch=loaded_test_input.shape[0],time=20), spatial(axis=33), channel(projection='x,y'))\n",
    "print(observation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:35.741016Z",
     "iopub.status.busy": "2022-07-09T09:52:35.740422Z",
     "iopub.status.idle": "2022-07-09T09:52:35.74939Z",
     "shell.execute_reply": "2022-07-09T09:52:35.748249Z",
     "shell.execute_reply.started": "2022-07-09T09:52:35.740978Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.24479,
     "end_time": "2022-06-28T07:37:55.571476",
     "exception": false,
     "start_time": "2022-06-28T07:37:55.326686",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reconstruction = math.random_normal(observation.shape.batch, spatial(x=33, y=33), channel(features='rho,vx,vy'))\n",
    "reconstruction = math.random_normal(observation_test.shape.batch, spatial(x=33, y=33), channel(features='rho,vx,vy'))\n",
    "# must have shape (batch, time=20, x=33, y=33, features=rho,vx,vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T09:52:35.751846Z",
     "iopub.status.busy": "2022-07-09T09:52:35.751236Z",
     "iopub.status.idle": "2022-07-09T09:53:14.629354Z",
     "shell.execute_reply": "2022-07-09T09:53:14.626834Z",
     "shell.execute_reply.started": "2022-07-09T09:52:35.751807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameter Count:\n",
      "29258\n",
      "Epoch: 0, Time Step: 0,Loss: 144911.5625\n",
      "Epoch: 0, Time Step: 5,Loss: 139219.390625\n",
      "Epoch: 0, Time Step: 10,Loss: 137983.703125\n",
      "Epoch: 0, Time Step: 15,Loss: 131758.671875\n",
      "Epoch: 1, Time Step: 0,Loss: 94877.859375\n",
      "Epoch: 1, Time Step: 5,Loss: 90063.140625\n",
      "Epoch: 1, Time Step: 10,Loss: 82288.140625\n",
      "Epoch: 1, Time Step: 15,Loss: 72600.984375\n",
      "Epoch: 2, Time Step: 0,Loss: 35682.8125\n",
      "Epoch: 2, Time Step: 5,Loss: 37799.9140625\n",
      "Epoch: 2, Time Step: 10,Loss: 42952.2421875\n",
      "Epoch: 2, Time Step: 15,Loss: 45834.40625\n",
      "Epoch: 3, Time Step: 0,Loss: 19282.7578125\n",
      "Epoch: 3, Time Step: 5,Loss: 28332.26953125\n",
      "Epoch: 3, Time Step: 10,Loss: 36253.17578125\n",
      "Epoch: 3, Time Step: 15,Loss: 42032.58203125\n",
      "Epoch: 4, Time Step: 0,Loss: 17962.763671875\n",
      "Epoch: 4, Time Step: 5,Loss: 27890.03515625\n",
      "Epoch: 4, Time Step: 10,Loss: 35848.21875\n",
      "Epoch: 4, Time Step: 15,Loss: 41460.140625\n",
      "Epoch: 5, Time Step: 0,Loss: 17500.771484375\n",
      "Epoch: 5, Time Step: 5,Loss: 27310.38671875\n",
      "Epoch: 5, Time Step: 10,Loss: 35211.828125\n",
      "Epoch: 5, Time Step: 15,Loss: 40784.50390625\n",
      "Epoch: 6, Time Step: 0,Loss: 17337.00390625\n",
      "Epoch: 6, Time Step: 5,Loss: 26979.767578125\n",
      "Epoch: 6, Time Step: 10,Loss: 34829.41015625\n",
      "Epoch: 6, Time Step: 15,Loss: 40212.96875\n",
      "Epoch: 7, Time Step: 0,Loss: 17615.5390625\n",
      "Epoch: 7, Time Step: 5,Loss: 31313.84375\n",
      "Epoch: 7, Time Step: 10,Loss: 39913.0859375\n",
      "Epoch: 7, Time Step: 15,Loss: 43393.7578125\n",
      "Epoch: 8, Time Step: 0,Loss: 17563.306640625\n",
      "Epoch: 8, Time Step: 5,Loss: 28064.76171875\n",
      "Epoch: 8, Time Step: 10,Loss: 35580.9296875\n",
      "Epoch: 8, Time Step: 15,Loss: 41187.625\n",
      "Epoch: 9, Time Step: 0,Loss: 17417.09375\n",
      "Epoch: 9, Time Step: 5,Loss: 27129.55859375\n",
      "Epoch: 9, Time Step: 10,Loss: 35231.16796875\n",
      "Epoch: 9, Time Step: 15,Loss: 40843.5\n"
     ]
    }
   ],
   "source": [
    "#print(label.features['rho'])\n",
    "proj_rho_x = math.sum(label.features['rho'], dim='y')\n",
    "proj_rho_y = math.sum(label.features['rho'], dim='x')\n",
    "proj = proj_rho_x + proj_rho_y\n",
    "\n",
    "#model = u_net(2, 3, levels=4, filters=[4, 8, 8, 4], in_spatial=2)\n",
    "class conv_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_module(f'conv_1',nn.Conv2d(2, 4, 3, 1, 1) )\n",
    "        self.add_module(f'conv_2', nn.Conv2d(4, 4, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip1', nn.Conv2d(2, 4, 1))\n",
    "\n",
    "        self.add_module(f'conv_3', nn.Conv2d(4, 8, 3, 1, 1))\n",
    "        self.add_module(f'conv_4', nn.Conv2d(8, 8, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip3', nn.Conv2d(4, 8, 1))\n",
    "\n",
    "        self.add_module(f'conv_5', nn.Conv2d(8, 16, 3, 1, 1))\n",
    "        self.add_module(f'conv_6', nn.Conv2d(16, 16, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip5', nn.Conv2d(8, 16, 1))\n",
    "        \n",
    "        self.add_module(f'conv_7', nn.Conv2d(16, 32, 3, 1, 1))\n",
    "        self.add_module(f'conv_8', nn.Conv2d(32, 32, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip7', nn.Conv2d(16, 32, 1))\n",
    "        \n",
    "        self.add_module(f'conv_9', nn.Conv2d(32, 16, 3, 1, 1))\n",
    "        self.add_module(f'conv_10', nn.Conv2d(16, 16, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip9', nn.Conv2d(32, 16, 1))\n",
    "        \n",
    "        self.add_module(f'conv_11', nn.Conv2d(16, 8, 3, 1, 1))\n",
    "        self.add_module(f'conv_12', nn.Conv2d(8, 8, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip11', nn.Conv2d(16, 8, 1))\n",
    "        \n",
    "        self.add_module(f'conv_13', nn.Conv2d(8, 4, 3, 1, 1))\n",
    "        self.add_module(f'conv_14', nn.Conv2d(4, 4, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip13', nn.Conv2d(8, 4, 1))\n",
    "\n",
    "        self.add_module(f'conv_15', nn.Conv2d(4, 3, 3, 1, 1))\n",
    "        self.add_module(f'conv_16', nn.Conv2d(3, 3, 3, 1, 1))\n",
    "        self.add_module(f'conv_skip15', nn.Conv2d(4, 3, 1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(1,15, 2):\n",
    "            x1 = F.relu(getattr(self, f'conv_{i}')(x)) \n",
    "            x = F.relu(getattr(self, f'conv_{i+1}')(x1) + getattr(self, f'conv_skip{i}')(x))\n",
    "        x1 = F.relu(getattr(self, 'conv_15')(x))\n",
    "        x = getattr(self, 'conv_16')(x1) + getattr(self, 'conv_skip15')(x) \n",
    "        return x \n",
    "\n",
    "\n",
    "model = conv_net().to('cuda')\n",
    "#model = U_net(2, 3, 6)\n",
    "print('Model Parameter Count:')\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "optim = adam(model, learning_rate=1e-3)\n",
    "def loss_fn(proj, u):\n",
    "    #proj = math.sum(u.features['rho'], dim='y') + math.sum(u.features['rho'], dim='x')\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        #print(i)\n",
    "        proj = math.expand(math.rename_dims(proj, 'axis', 'axis_x') , spatial(axis_y=33))\n",
    "        pred = math.native_call(model, proj)\n",
    "        #print('proj_shape')\n",
    "        #print(proj.shape)\n",
    "        #print(pred.shape)\n",
    "        pred = math.tensor(pred, batch(batch=Nb), channel(features='rho,vx,vy'), spatial(x=33, y=33))\n",
    "        #print(pred)\n",
    "        loss += math.l2_loss(pred - u)\n",
    "        #u = step(u)\n",
    "        u = step(u)\n",
    "        #print(u_m.shape)\n",
    "        proj_x = math.sum(pred.features['rho'], dim='y')\n",
    "        proj_x = math.reshaped_native(proj_x, ('batch', 'x'))\n",
    "        proj_y = math.sum(pred.features['rho'], dim='x')\n",
    "        proj_y = math.reshaped_native(proj_y, ('batch', 'y'))\n",
    "        \n",
    "        proj_x = torch.unsqueeze(proj_x, 2)\n",
    "        proj_y = torch.unsqueeze(proj_y, 2)\n",
    "        proj = torch.concat([proj_x, proj_y], 2)\n",
    "        proj = math.tensor(proj,batch(batch=Nb), spatial(axis=33) , channel(projection='x,y'))\n",
    "    return math.sum(loss, 'batch')\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for t in range(0,Nt):\n",
    "        proj = observation.time[t]\n",
    "        u = label.time[t]\n",
    "        #print('Training Loop Shapes:')\n",
    "        #print(proj.shape)\n",
    "        #print(u.shape)\n",
    "        loss = update_weights(model, optim, loss_fn, proj, u)\n",
    "        if t%5==0:\n",
    "            print(f'Epoch: {epoch}, Time Step: {t},Loss: {loss}')\n",
    "\n",
    "#reconstruction = math.native_call(model, observation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T00:24:14.610238Z",
     "iopub.status.idle": "2022-07-09T00:24:14.613752Z",
     "shell.execute_reply": "2022-07-09T00:24:14.613499Z",
     "shell.execute_reply.started": "2022-07-09T00:24:14.613472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(timeᵇ=20, batchᵇ=1, xˢ=33, yˢ=33, featuresᶜ=rho,vx,vy)\n",
      "(batchᵇ=1, timeᵇ=20, xˢ=33, yˢ=33, featuresᶜ=rho,vx,vy)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Nbt = 1 #Test Batches\n",
    "proj = math.expand(math.rename_dims(observation_test.time[0], 'axis', 'axis_x') , spatial(axis_y=33))\n",
    "#print(proj.shape)\n",
    "pred = math.native_call(model, proj)\n",
    "\n",
    "pred = math.tensor(pred, batch(batch=Nbt), channel(features='rho,vx,vy'), spatial(x=33, y=33))\n",
    "\n",
    "reconstruction = pred\n",
    "#print(pred.shape)\n",
    "reconstruction = math.expand(reconstruction, batch(time=1))\n",
    "for t in range(1,20):\n",
    "    proj = math.expand(math.rename_dims(observation_test.time[t], 'axis', 'axis_x') , spatial(axis_y=33))\n",
    "    pred = math.native_call(model, proj)\n",
    "    \n",
    "    pred = math.tensor(pred, batch(batch=Nbt), channel(features='rho,vx,vy'), spatial(x=33, y=33))\n",
    "    pred = math.expand(pred, batch(time=1))\n",
    "    \n",
    "    reconstruction = math.concat( [reconstruction, pred], 'time')\n",
    "\n",
    "print(reconstruction.shape)\n",
    "reconstruction = math.reshaped_native(reconstruction, ('time', 'batch', 'x', 'y', 'features'))#batch(time=20, batch=1),spatial(x=33, y=33), channel(features='rho,vx,vy'))\n",
    "reconstruction = torch.permute(reconstruction, [1, 0, 2,3,4])\n",
    "reconstruction = math.tensor(reconstruction, batch(batch=1, time=20), spatial(x=33, y=33), channel(features='rho,vx,vy'))\n",
    "print(reconstruction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006476,
     "end_time": "2022-06-28T07:37:55.586751",
     "exception": false,
     "start_time": "2022-06-28T07:37:55.580275",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**Do not edit the following cell!**\n",
    "Finally, we compute the physics and projection match loss. The following cell must execute last in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T00:24:14.617658Z",
     "iopub.status.idle": "2022-07-09T00:24:14.618452Z",
     "shell.execute_reply": "2022-07-09T00:24:14.618198Z",
     "shell.execute_reply.started": "2022-07-09T00:24:14.618174Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.814469,
     "end_time": "2022-06-28T07:37:56.406704",
     "exception": false,
     "start_time": "2022-06-28T07:37:55.592235",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert reconstruction.shape == observation_test.shape.batch & spatial(x=33, y=33) & channel(features='rho,vx,vx'), \"Reconstruction does not have the correct shape!\"\n",
    "\n",
    "from phi.field._grid import unstack_staggered_tensor\n",
    "def cen_to_stag(centered_grid):\n",
    "    padded_values = math.pad(centered_grid.values, {'x':(0,1), 'y':(0,1)}, mode=math.extrapolation.ZERO)\n",
    "    return padded_values\n",
    "\n",
    "def reduce_to_cen(reduce_tensor):\n",
    "    return math.pad(reduce_tensor, {'x':(0,-1), 'y':(0,-1)}, mode=math.extrapolation.BOUNDARY)\n",
    "\n",
    "def step(state, dt=5.):\n",
    "    s = CenteredGrid(reduce_to_cen(state.features['rho']), extrapolation.BOUNDARY, x=32, y=32, bounds=Box(x=100, y=100))\n",
    "    unstacked_velocity = unstack_staggered_tensor(math.rename_dims(state.features['vx,vy'], 'features', 'vector'), extrapolation=math.extrapolation.ZERO)\n",
    "    v = StaggeredGrid(unstacked_velocity, 0, x=32, y=32, bounds=Box(x=100, y=100))\n",
    "    s = advect.mac_cormack(s, v, dt) #+ INFLOW\n",
    "    buoyancy = s * (0, 0.1) @ v  # resamples smoke to velocity sample points\n",
    "    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt\n",
    "    v,_= fluid.make_incompressible(v, (), Solve('auto', 1e-5, 0))\n",
    "    v = v.staggered_tensor()\n",
    "    return math.stack([cen_to_stag(s), v.vector['x'], v.vector['y']], channel(features='rho,vx,vy'))\n",
    "\n",
    "phys_loss = math.l2_loss(step(reconstruction).time[:-1] - reconstruction.time[1:]).numpy('batch,time').flatten()\n",
    "proj_x = math.sum(reconstruction.features['rho'], 'x').numpy('batch,time,y').flatten()\n",
    "proj_y = math.sum(reconstruction.features['rho'], 'y').numpy('batch,time,x').flatten()\n",
    "numpy.savetxt('result.csv', numpy.concatenate([phys_loss, proj_x, proj_y]), delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T00:24:14.619855Z",
     "iopub.status.idle": "2022-07-09T00:24:14.627025Z",
     "shell.execute_reply": "2022-07-09T00:24:14.6267Z",
     "shell.execute_reply.started": "2022-07-09T00:24:14.626671Z"
    },
    "papermill": {
     "duration": 0.026285,
     "end_time": "2022-06-28T07:37:56.438333",
     "exception": false,
     "start_time": "2022-06-28T07:37:56.412048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1339,)\n"
     ]
    }
   ],
   "source": [
    "result = np.concatenate([phys_loss, proj_x, proj_y], axis = 0)\n",
    "print(result.shape)\n",
    "submission_df = pd.DataFrame(data = {'Id':np.arange(result.shape[0]), 'Expected':result})\n",
    "submission_df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.00485,
     "end_time": "2022-06-28T07:37:56.4488",
     "exception": false,
     "start_time": "2022-06-28T07:37:56.44395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
